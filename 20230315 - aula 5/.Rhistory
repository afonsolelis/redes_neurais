knitr::opts_chunk$set(echo = TRUE)
# Carregando bibliotecas
library(cvTools)
library(RSNNS)
# Função para calcular a acurácia
calc_acuracia <- function(y_desejado, y_estimado) {
matriz_confusao <- table(y_desejado, y_estimado)
acuracia <- sum(diag(matriz_confusao)) / length(y_desejado)
return(acuracia * 100)
}
# Configurando a validação cruzada
db_iris <- iris
n <- dim(db_iris)[1]
K <- 5
pastas <- cvFolds(n, K, type = "random")
acuracias <- numeric(K)
for (pasta in 1:K) {
i_treino <- which(pastas$which != pasta)
i_teste <- which(pastas$which == pasta)
# Preparando os dados de treino e teste
X_treino <- db_iris[i_treino, -5]
X_teste <- db_iris[i_teste, -5]
classes_bin_treino <- decodeClassLabels(db_iris$Species[i_treino])
classes_bin_teste <- decodeClassLabels(db_iris$Species[i_teste])
# Treinando o modelo
model <- mlp(X_treino, classes_bin_treino, size = c(2, 3), learnFuncParams = c(0.9),
maxit = 100, learnFunc = "Std_Backpropagation",
hiddenActFunc = "Act_Logistic", inputsTest = X_teste,
targetsTest = classes_bin_teste, linOut = FALSE)
# Fazendo a previsão
y_estimado <- predict(model, X_teste)
y_estimado <- matrix(apply(y_estimado, 1, which.max), ncol = 1)
colnames(y_estimado) <- "Estimado"
y_estimado <- colnames(classes_bin_treino)[y_estimado]
# Calculando a acurácia
acuracias[pasta] <- calc_acuracia(db_iris$Species[i_teste], y_estimado)
# Plotando o gráfico de erro
plotIterativeError(model, main = paste("Erro Iterativo - Fold", pasta))
}
# Acurácia média
acuracia_media <- mean(acuracias)
print(acuracia_media)
# Instalação da biblioteca cross-validation
# install.packages("cvTools")
library(cvTools)
library(nnet)
# Função para calcular a acurácia
calcular_acuracia <- function(valores_reais, valores_preditos) {
return(mean(valores_reais == valores_preditos))
}
# Exemplo para a base iris
db_iris <- iris
n <- dim(db_iris)[1]
K <- 5
pastas <- cvFolds(n, K, type = "random")
# Inicializando variáveis para armazenar as acurácias
acuracia_kfold <- numeric(K)
acuracia_mlp <- numeric(K)
for (pasta in 1:K) {
# Separando os índices para treino e teste
i_treino <- which(pastas$which != pasta)
i_teste <- which(pastas$which == pasta)
# Criando os conjuntos de treino e teste
db_treino <- db_iris[i_treino, ]
db_teste <- db_iris[i_teste, ]
# Treinando o modelo de regressão logística
modelo_logistico <- multinom(Species ~ ., data = db_treino)
# Treinando o modelo MLP
modelo_mlp <- nnet(Species ~ ., data = db_treino, size = 10, MaxNWts = 1000, maxit = 200, trace = FALSE)
# Realizando as predições com os modelos treinados
predicoes_logistico <- predict(modelo_logistico, newdata = db_teste)
predicoes_mlp <- predict(modelo_mlp, newdata = db_teste, type = "class")
# Calculando a acurácia dos modelos
acuracia_kfold[pasta] <- calcular_acuracia(db_teste$Species, predicoes_logistico)
acuracia_mlp[pasta] <- calcular_acuracia(db_teste$Species, predicoes_mlp)
}
# Calculando a acurácia média dos modelos
acuracia_media_kfold <- mean(acuracia_kfold)
acuracia_media_mlp <- mean(acuracia_mlp)
cat("Acurácia média do modelo de regressão logística com K-fold cross-validation:", acuracia_media_kfold, "\n")
cat("Acurácia média do modelo MLP:", acuracia_media_mlp, "\n")
# Medida de Desempenho
y_estimado <- c(1, 1, 1, 2, 2, 2, 2, 3, 3, 3)
y_desejado <- c(1, 1, 1, 1, 2, 2, 2, 1, 2, 3)
matriz_confusao <- table(y_desejado, y_estimado)
acuracia <- sum(diag(matriz_confusao)) / length(y_desejado)
print(acuracia * 100)
# Instalar a biblioteca RSNNS
# install.packages("RSNNS")
# Curva ROC
y_desejado <- c(0, 0, 0, 0, 1, 1, 1, 1, 1)
y_estimado <- c(0, 0, 0, 1, 1, 0, 1, 1, 1)
# Converter as classes para probabilidades
y_estimado_prob <- ifelse(y_estimado == 1, 1, 0)
# Instalar a biblioteca pROC
# install.packages("pROC")
library("pROC")
# Criar a curva ROC
roc_obj <- roc(y_desejado, y_estimado_prob)
# Plotar a curva ROC
plot(roc_obj, main = "Curva ROC")
# Carregando as bibliotecas necessárias
library(neuralnet)
library(mltools)
library(data.table)
library(caret)
library(pROC)
# Carregando o dataset iris e normalizando os dados das colunas numéricas
iris2 = scale(iris[,1:4])
iris2 = as.data.frame(iris2)
iris2$Species = iris$Species
# Definindo a semente aleatória
set.seed(1234)
# Definindo o número de folds e criando a lista de folds
k <- 5
folds <- createFolds(iris2$Species, k = k)
# Inicializando os vetores de acurácia e de curvas ROC
accuracy <- vector(mode = "numeric", length = k)
roc_list <- list()
# Loop principal que realiza o processo de treinamento e teste para cada fold
for(i in 1:k) {
# Dividindo o dataset em conjunto de treinamento e teste
iristreino <- iris2[folds[[i]], ]
iristeste <- iris2[-folds[[i]], ]
# Transformando a variável Species em one-hot encoding para utilização na rede neural
iristreino <- cbind(iristreino[,1:4], one_hot(as.data.table(iristreino[,5])))
# Treinando a rede neural com a função neuralnet, com duas camadas ocultas
modelo <- neuralnet(V1_setosa + V1_versicolor + V1_virginica ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, iristreino, hidden=c(5,4))
# Plotando a rede neural treinada
print(modelo)
# Testando a rede neural no conjunto de teste e obtendo as predições
teste <- compute(modelo, iristeste[,1:4])
resultado <- as.data.frame(teste$net.result)
# Renomeando as colunas das predições para as espécies de iris
names(resultado)[1] <- 'setosa'
names(resultado)[2] <- 'versicolor'
names(resultado)[3] <- 'virginica'
# Atribuindo a espécie com maior probabilidade como a predição final
resultado$class <- colnames(resultado[,1:3])[max.col(resultado[,1:3], ties.method = 'first')]
# Criando a tabela de confusão e imprimindo no console
confusao <- table(resultado$class, iristeste$Species)
print(confusao)
# Calculando a acurácia do modelo para o fold atual e adicionando à lista de acurácias
accuracy[i] <- sum(diag(confusao) * 100 / sum(confusao))
}
# Calculando a acurácia média do modelo em todos os folds
mean(accuracy)
# Definindo a disposição dos plots em uma janela gráfica
par(mfrow=c(2,2))
# Plotando todas as redes neurais treinadas em uma única janela gráfica
for(i in 1:length(modelo$weights)) {
plot(modelo, rep = "best", show.weights = i)
}
